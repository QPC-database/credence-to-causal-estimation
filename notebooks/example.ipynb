{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREDENCE -  Credence to Causal Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premise. \n",
    "Retrospective causal inference methods, like synthetic controls or difference in difference, are widely used to estimate the impact of an intervention where A/B testing is not an option: for example, fee changes or marketing campaigns. The causal effect of an intervention is the difference between the outcome under a treatment and the counterfactual outcome if an alternative treatment (or no treatment) was chosen. The main challenge in retrospective and non-experimental causal inference is that we only observe the outcome under one of the treatment choices while the counterfactual is never observed. Causal inference methods aims to re-create the scenario in which the alternative treatment was chosen i.e. estimating the counterfactual.\n",
    "\n",
    "### Evaluation. \n",
    "Traditional causal inference methods are typically evaluated in two ways: placebo tests and tests on simulated data. Placebo tests check that the treatment effect estimated by a particular method is zero during a period there is actually no intervention: in that situation, the actual should match the counterfactual. Testing on simulated data is limited because the data generative process is often simple and lacks the complexities of real world datasets where the method is actually applied. For applied researchers, the important question is understanding how well a method actually performs in realistic situations, not on a toy dataset.\n",
    "\n",
    "### Framework. \n",
    "In this project, we propose and develop a framework for generating complex and realistic datasets with known treatment effects. This approach combines the best parts of placebo tests and simulation tests: the simulated dataset would have as much complexity as the real world datasets used in placebo tests, but users would be able to control the treatment effect as well as the level of endogeneity like they do in simulation tests.\n",
    "\n",
    "Thus, generated datasets can then be used to understand the performance of different causal inference methods on various metrics, allowing scientists to choose appropriate method for a given problem. Currently, we focus on causal inference with time-series data using synthetic control method(s). \n",
    "\n",
    "Our framework uses a neural network based black-box data generative model called Autoregressive Variational AutoEncoder (AR-VAE), and an interpretable transformation map (ITM) to learn the distribution and sample dataset which have similar dynamics as the real datasets of interest. The AR-VAE model allows us to generate complex data while the ITM allows us to manipulate and intervene on the samples to encode treatment effects. \n",
    "\n",
    "Code Commit Link - https://git-codecommit.us-east-1.amazonaws.com/v1/repos/credence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite python libraries\n",
    "Numpy, Math, Pytorch, Pytorchvision, Pytorch-lightning, Pandas, Matplotlib, Sys, OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import train_arvae\n",
    "import verify_causal_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use CREDENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credence has a 6 step procedure : 1. Train Data-Generator 2. Give Input Data 3. Design Intervention 4. Sample from the pretrained network 5. Choose Causal Method(s) 6. Evaluate the performance \n",
    "\n",
    "![Picture1.png](Picture1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Training Data\n",
    "Read training data and store it in form (T,B,N) where T is the number of time steps, B is the number of units, N is the number of time-series in a unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=100\n",
    "N=10\n",
    "\n",
    "training_data = pd.read_csv('gdpTrainingData.csv', header=0, index_col=0)\n",
    "training_data.iloc[:,[1,3]]\n",
    "num_rows, num_cols = training_data.shape\n",
    "for i in range(0,B):\n",
    "    col_idx = np.random.choice( num_cols, N)\n",
    "    data_i = training_data.iloc[:,col_idx].to_numpy().reshape(training_data.shape[0],1,-1)\n",
    "    if i == 0:\n",
    "        data = data_i\n",
    "    else:\n",
    "        data = np.concatenate((data,data_i),axis=1)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.mean(data)\n",
    "s = np.std(data)\n",
    "data_norm = (data-m)/s\n",
    "\n",
    "print(f\"Shape: {data_norm.shape}\")\n",
    "print(f\"\\nMean of raw data: {np.mean(data):.3f}\")\n",
    "print(f\"Std. dev of raw data: {np.std(data):.3f}\")\n",
    "print(f\"\\nMean of normalized data: {np.mean(data_norm):.3f}\")\n",
    "print(f\"Std. dev of normalized data: {np.std(data_norm):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ARVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {}\n",
    "hyper_params['lag'] = 4\n",
    "hyper_params['epochs'] = 10\n",
    "hyper_params['latent_dim'] = 8 #Z\n",
    "hyper_params['hidden_dims'] = [64,32]\n",
    "\n",
    "\n",
    "N = data_norm.shape[2] #target+#donors\n",
    "T = data_norm.shape[0] #length timeseries\n",
    "B = data_norm.shape[1] #number bundles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Running training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model, runner = train_arvae.train(data_norm, hyper_params, \n",
    "                          output_checkpoint_path='ar_vae.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arvae.plot( data_norm[:,:1,:], vae_model) #plotting an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Give Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv('input_data.csv',header=0, index_col=0)\n",
    "input_data = input_data.to_numpy().reshape(input_data.shape[0],1,-1)\n",
    "m = np.mean(input_data)\n",
    "s = np.std(input_data)\n",
    "input_data = (input_data-m)/s\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arvae.plot( input_data, vae_model) #plotting an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Calculate Marginal Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglike = vae_model.marginal_log_likelihood(torch.tensor(input_data).float(),samples=100)\n",
    "\n",
    "print(loglike[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervene\n",
    "\n",
    "**NOTE: As of 2020-09-14, there is a bug of unknown origin for the cell below when running `train_arvae.intervene_raw`. The command fails on an apparent mismatch between the size of hidden dimensions the first time that the cell is run, but succeeds if the cell is re-run. Source of bug needs to be determined and fixed.** - @kwillet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T0 = 50 #setting intervention time\n",
    "\n",
    "#define an arbitrary intervention function\n",
    "\n",
    "def intervention_fn(V):\n",
    "    A,B = V\n",
    "    A[:,0] = torch.exp(A[:,0])\n",
    "    A[:,1] = 1.025*A[:,1]\n",
    "    A[:,2] = A[:,2] + 0.001\n",
    "    B[0] = B[0] - 0.0006\n",
    "    B[1] = B[1] + 0.00045\n",
    "    return A,B\n",
    "\n",
    "vae_model_intv = train_arvae.intervene_raw( target_idx = [0,1],\n",
    "                               feature_idx = [0,-3,-4],\n",
    "                               bias = True,\n",
    "                               intervention = intervention_fn, \n",
    "                               checkpoint_path='ar_vae.ckpt', \n",
    "                               hyper_params=hyper_params, \n",
    "                               data=data_norm) #getting post-intervention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arvae.plot( input_data, vae_model, post_intervention_vae_model=vae_model_intv, T0=T0 ) #plotting an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Causal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Add path to local installation of REMI - change and uncomment if necessary\n",
    "\"\"\"\n",
    "\n",
    "# local_remi_path = \"/Users/kwillet/REMI/\"\n",
    "\n",
    "try:\n",
    "    sys.path.append(local_remi_path)\n",
    "except NameError:\n",
    "    print(\"No local path for REMI found; package must be in Python path to run verify_causal_model().\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_data = pd.read_csv('input_data.csv',header=0, index_col=0)\n",
    "input_data.rename(columns={input_data.columns[0]: 'y0'},inplace=True)\n",
    "\n",
    "TrueTE, EstTE = verify_causal_model.verify_causal_model(vae_model, \n",
    "                                    vae_model_intv, \n",
    "                                    T0, \n",
    "                                    input_data,\n",
    "                                    target = list(input_data.columns[:2]), \n",
    "                                    donors = list(input_data.columns[2:]),\n",
    "                                    method = 'REMI',\n",
    "                                    number_samples = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TrueTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EstTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
